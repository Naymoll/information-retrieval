# Задание

1. Извлеките документы. Коллекция документов состоит из 10 xml-файлов, содержание и URL закодированы в base64 + cp1251. Коллекцию скачать [здесь](https://drive.google.com/file/d/1xV7Z0POUYEOnTOCXc_UsxP3-ihUI-g_q/view). Пример разметки [здесь](http://romip.ru/docs/sample-document1.xml)
2. Удалите HTML-разметку (например, с помощью [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)). Сохраните отдельно информацию о гиперссылках
3. Проиндексируйте коллекцию с помощью Elasticsearch
4. Оцените качество поиска по формуле BM25, используя “слабую” (OR) оценку релевантности РОМИП 2009 года, посчитайте метрики: p@20, r@20, MAP@20, R-precision
    - Тексты запросов: http://romip.ru/tasks/2008/web2008_adhoc.xml.bz2
    - Оценки релевантности: https://wiki.compscicenter.ru/images/1/1c/Relevance_table_2009.xml.zip
5. Проиндексируйте коллекцию с морфологической обработкой.(лемматизация, удаление стоп слов)
    - Использовать фильтр Snowball в Elasticsearch или индексирование предварительно лемматизированных документов (pymystem3)
    - Сравните качество поиска с вариантом без морфологии
6. Рассчитайте PageRank страниц
7. Постройте граф гиперссылок между страницами коллекции, визуализируйте (например, с помощью gephi)

# Запуск

## Зависимости
Список зависимостей указан в файле `requirements.txt`.

## Файл main.py
Парсит содержимое коллекций в папке `data` и индексирует документы в `elasticsearch`.

## Файл metrics.py
Парсит `web2008_adhoc.xml` и `relevant_table_2009.xml`. Рассчитывает метрики индексов из `elasticsearch`.